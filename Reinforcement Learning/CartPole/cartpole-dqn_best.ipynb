{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 2_000\n",
    "RANDOM_RUNS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.05\n",
    "EXPLORATION_DECAY = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.run_memory = []\n",
    "\n",
    "        # load dataset if exist\n",
    "        if os.path.exists(\"datasets\\\\best_memory_dqn.pkl\"):\n",
    "            with open(\"datasets\\\\best_memory_dqn.pkl\", 'rb') as file:\n",
    "                print(\"loaded old best memory\")\n",
    "                self.best_memory = pickle.load(file)\n",
    "        else:\n",
    "            self.best_memory = []\n",
    "\n",
    "        if os.path.exists(\"models\\\\model_dqn.hdf5\"):           \n",
    "            self.model = models.load_model(\"models\\\\model_dqn.hdf5\")\n",
    "            print('loaded model')\n",
    "            \n",
    "            self.isFit=True\n",
    "            self.exploration_rate=EXPLORATION_MIN*2\n",
    "        else:\n",
    "            self.model = Sequential()\n",
    "            self.model.add(Dense(48, input_shape=(observation_space,), activation=\"relu\"))\n",
    "            self.model.add(Dense(24, activation=\"relu\"))\n",
    "            self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "            self.model.compile(loss=\"mse\", optimizer=Adam(learning_rate=LEARNING_RATE))\n",
    "            self.isFit = False\n",
    "            self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "    def short_remember(self, state, action, reward, next_state, done):\n",
    "        self.run_memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "    def long_remember(self, step):\n",
    "        self.best_memory.append((self.run_memory.copy(), step))\n",
    "        self.run_memory.clear()\n",
    "        # print(len(self.run_memory), len(self.best_memory), MEMORY_SIZE)\n",
    "        \n",
    "        if len(self.best_memory) > MEMORY_SIZE:\n",
    "            # print(len(self.run_memory), len(self.best_memory))\n",
    "            self.best_memory = sorted(self.best_memory, key=lambda x: x[1])\n",
    "            self.best_memory = self.best_memory[-MEMORY_SIZE:]\n",
    "            return True\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            # print(\"Random\")\n",
    "            return random.randrange(self.action_space)\n",
    "        if self.isFit == True:\n",
    "            # print(\"Predict\")\n",
    "            q_values = self.model.predict(state, verbose=0)\n",
    "        else:\n",
    "            q_values = np.zeros(self.action_space).reshape(1, -1)\n",
    "            \n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "\n",
    "    def experience_replay(self):\n",
    "        # print(\"Experience replay\")\n",
    "        if len(self.best_memory) < BATCH_SIZE:\n",
    "            return\n",
    "    \n",
    "        batch = self.best_memory[-BATCH_SIZE//2:] + random.sample(self.best_memory, BATCH_SIZE//2)\n",
    "        all_frames = np.array(sum([b for b, step in batch], []), dtype='object')\n",
    "        len_frames = all_frames.shape[0]\n",
    "        # print(\"Total frames to train\", len_frames)\n",
    "        # X_v = np.empty((len_frames, 4))\n",
    "        # y_v = np.empty((len_frames, 2))\n",
    "\n",
    "        rewards = all_frames[:, 2]\n",
    "        states_next = np.concatenate(all_frames[:, 3])\n",
    "        terminals = all_frames[:, 4]\n",
    "        states = np.concatenate(all_frames[:, 0])\n",
    "        actions = all_frames[:, 1].astype('int8')\n",
    "\n",
    "        # already fit model\n",
    "        if self.isFit:\n",
    "            q_values = self.model.predict(states, verbose=0).astype('float')\n",
    "            q_updates = np.where(terminals, rewards, (rewards + GAMMA * np.amax(self.model.predict(states_next, verbose=0), axis=1)).astype('float'))\n",
    "        else:\n",
    "            q_values = np.zeros((len_frames, self.action_space))\n",
    "            q_updates = rewards\n",
    "            \n",
    "        q_v0 = np.where(actions==0, q_updates, q_values[:, 0]).reshape(-1,1)\n",
    "        #q_v0 = np.where(terminal, rewards, q_v0).reshape(-1, 1) # q_values[0, 1], q_values[1,0], q_values[2, 1]\n",
    "        q_v1 = np.where(actions==1, q_updates, q_values[:, 1]).reshape(-1,1)\n",
    "        # q_v1 = np.where(terminal, rewards, q_v1).reshape(-1, 1)# q_values[0, 1], q_values[1,0], q_values[2, 1]\n",
    "\n",
    "        y_v = np.concatenate((q_v0, q_v1), axis=1)\n",
    "        X_v = states\n",
    "        \n",
    "        # print(reward)\n",
    "        # print(\" Training \".center(80, '*'))\n",
    "        # print(X)\n",
    "        # print(y)\n",
    "        self.model.fit(X_v.astype('float64'), y_v.astype('float64'), epochs=5, verbose=0)\n",
    "        self.isFit = True\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"models\\\\model_lightGBM.pkl\"):\n",
    "    with open(\"models\\\\model_lightGBM.pkl\", 'rb') as file:\n",
    "        lbm = pickle.load(file)\n",
    "        # print('loaded model')\n",
    "        \n",
    "env = gym.make(ENV_NAME)\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "batch = dqn_solver.best_memory[-BATCH_SIZE//2:] + random.sample(dqn_solver.best_memory, BATCH_SIZE//2)\n",
    "all_frames = np.array(sum([b for b, step in batch], []), dtype='object')\n",
    "len_frames = all_frames.shape[0]\n",
    "\n",
    "rewards = all_frames[:, 2]\n",
    "states_next = np.concatenate(all_frames[:, 3])\n",
    "terminals = all_frames[:, 4]\n",
    "states = np.concatenate(all_frames[:, 0])\n",
    "actions = all_frames[:, 1].astype('int8')\n",
    "\n",
    "q_values = lbm.predict(states).astype('float')\n",
    "q_updates = np.where(terminals, rewards, (rewards + GAMMA * np.amax(lbm.predict(states_next), axis=1)).astype('float'))\n",
    "      \n",
    "q_v0 = np.where(actions==0, q_updates, q_values[:, 0]).reshape(-1,1)\n",
    "q_v1 = np.where(actions==1, q_updates, q_values[:, 1]).reshape(-1,1)\n",
    "\n",
    "y_v = np.concatenate((q_v0, q_v1), axis=1)\n",
    "X_v = states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer algorithm on dqn\n",
    "if not dqn_solver.isFit:\n",
    "    dqn_solver.model.fit(X_v.astype('float64'), y_v.astype('float64'), epochs=2)\n",
    "    # y_dqn = dqn_solver.model.predict(X_v, verbose=0)\n",
    "    dqn_solver.isFit = True\n",
    "    dqn_solver.exploration_rate = EXPLORATION_MIN*2\n",
    "\n",
    "y_dqn = dqn_solver.model.predict(X_v, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y_v, y_dqn), dqn_solver.isFit, dqn_solver.exploration_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%prun \n",
    "# env = gym.make(ENV_NAME)\n",
    "# observation_space = env.observation_space.shape[0]\n",
    "# action_space = env.action_space.n\n",
    "#dqn_solver = LightQSolver(observation_space, action_space)\n",
    "run = RANDOM_RUNS-1\n",
    "steps = []\n",
    "\n",
    "while True:\n",
    "    run += 1\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, observation_space])\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        # env.render()\n",
    "        action = dqn_solver.act(state)\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        reward = reward if not terminal else -reward\n",
    "        state_next = np.reshape(state_next, [1, observation_space])\n",
    "        dqn_solver.short_remember(state, action, reward, state_next, terminal)\n",
    "        state = state_next\n",
    "        if terminal: \n",
    "            print(\"#\", end='')\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "    dqn_solver.long_remember(step)\n",
    "\n",
    "    if run % 100 == 0 and run >= RANDOM_RUNS:\n",
    "        dqn_solver.experience_replay()\n",
    "\n",
    "        print(\"\\nRun: \" + str(run) + \", exploration: \" + str(round(dqn_solver.exploration_rate,3)) + #\", last score: \" + str(step) + \n",
    "            f\" | Best memory -> Best: {dqn_solver.best_memory[-1][-1]}, Mean: {np.mean([x[1] for x in dqn_solver.best_memory]):.2f}, Worst: {dqn_solver.best_memory[0][-1]}\", \n",
    "            f\"| Last 100 runs -> Best: {max(steps)}, Mean: {np.mean(steps):.2f}, Worst: {min(steps)}\")\n",
    "        \n",
    "        steps.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [print(b[0][0], x) for b, x in dqn_solver.best_memory];\n",
    "# # save dataset\n",
    "# with open(\"datasets\\\\best_memory_dqn.pkl\", 'wb') as file:\n",
    "#     print(file)\n",
    "#     pickle.dump(dqn_solver.best_memory, file)\n",
    "\n",
    "# with open(\"models\\\\model_dqn.pkl\", 'wb') as file:\n",
    "#     print(file, dqn_solver.model)\n",
    "#     dqn_solver.model.save(\"models\\\\model_dqn.hdf5\")\n",
    "\n",
    "# # previous method\n",
    "# X = np.empty((len_frames, 4))\n",
    "# y = np.empty((len_frames, 2))\n",
    "# step_cntr = 0\n",
    "\n",
    "# for b, step in batch:\n",
    "#     for i, (state, action, reward, state_next, terminal) in enumerate(b):\n",
    "#         #print(i+step_cntr, end=\",\")\n",
    "#         q_update = reward\n",
    "#         if not terminal:\n",
    "#             if dqn_solver.isFit:\n",
    "#                 q_update = (reward + GAMMA * np.amax(dqn_solver.model.predict(state_next)[0]))\n",
    "#                 # print(self.model.predict(state_next))\n",
    "#             else:\n",
    "#                 q_update = reward\n",
    "#         if dqn_solver.isFit:\n",
    "#             q_values = dqn_solver.model.predict(state)\n",
    "#         else:\n",
    "#             q_values = np.zeros(dqn_solver.action_space).reshape(1, -1)\n",
    "            \n",
    "#         q_values[0][action] = q_update\n",
    "\n",
    "#         X[i+step_cntr] = state[0]\n",
    "#         y[i+step_cntr] = q_values[0]\n",
    "                    \n",
    "#     step_cntr += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [[\"ok\", 1], [\"?\", 3]]\n",
    "t.append([\"va\", 1])\n",
    "t.append([\"come\", 3])\n",
    "\n",
    "sorted(t, key=lambda x: x[1]), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X[:] == X_v[:]).all(), (y[:] == y_v[:]).all(), y_v[499], y[499], X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"(Best: {dqn_solver.best_memory[-1][-1]}, Worst: {dqn_solver.best_memory[0][-1]})\")\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# # print([x[1] for x in sorted(dqn_solver.best_memory, key=lambda x: x[1])])\n",
    "# if len(dqn_solver.best_memory) > MEMORY_SIZE:\n",
    "#     # print(len(dqn_solver.run_memory), len(dqn_solver.best_memory))\n",
    "#     dqn_solver.best_memory = sorted(dqn_solver.best_memory, key=lambda x: x[1])\n",
    "#     dqn_solver.best_memory = dqn_solver.best_memory[-MEMORY_SIZE:]\n",
    "    \n",
    "# print(f\"(Best: {dqn_solver.best_memory[-1][-1]}, Worst: {dqn_solver.best_memory[0][-1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "step_counter = 0\n",
    "for bm in dqn_solver.best_memory[-100:]:\n",
    "    for i,(state, action, reward, state_next, terminal) in enumerate(bm[0]):\n",
    "        pass\n",
    "        #print(i+step_counter)\n",
    "    step_counter += bm[1]\n",
    "sum([x[1] for x in dqn_solver.best_memory[-100:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = []\n",
    "best_index = []\n",
    "all_data = deque(maxlen=100)\n",
    "max_len = 100\n",
    "import bisect\n",
    "\n",
    "for i in range(1000):\n",
    "    r = random.randint(0, 100)\n",
    "    all_data.append([r,str(i)])\n",
    "\n",
    "    if len(best_params) < max_len:\n",
    "        best_params.append(r)\n",
    "        if len(best_params) == max_len-1:\n",
    "            best_params = sorted(best_params)\n",
    "\n",
    "    bisect.insort(best_params, r)\n",
    "    best_params = best_params[-max_len:]\n",
    "        # best_index = np.argsort(best_params)[-10:]\n",
    "    \n",
    "        \n",
    "print(type(all_data))\n",
    "print(type(sorted(all_data, key=lambda x: x[1])[:4]))\n",
    "all_data.append(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.insert(len(np.array(best_params)[(np.array(best_params) < 20)]), 20)\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "def bisect_insert(best_params):\n",
    "    bisect.insort(best_params, 20)\n",
    "    return best_params[-10:]\n",
    "\n",
    "def sorted_insert(best_params):\n",
    "    best_params.append(20)\n",
    "    best_params = sorted(best_params)\n",
    "    return best_params[-10:]\n",
    "\n",
    "def sorted_numpy(best_params, arg):\n",
    "    #print(arg, best_params[best_params<arg])\n",
    "    best_params = np.insert(best_params, len(best_params[best_params<arg]), arg)[-max_len:]\n",
    "    return best_params\n",
    "\n",
    "# %timeit bisect_insert(best_params)\n",
    "# %timeit sorted_numpy(np.array(best_params).copy(), 20)\n",
    "print(sorted_numpy(np.array(best_params).copy(), 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "times = []\n",
    "best_par = np.array(best_params).copy()\n",
    "\n",
    "for i in range(100000):\n",
    "    t = time.time()\n",
    "    best_par = sorted_numpy(best_par, random.randint(70, 95))\n",
    "    t2 = time.time()-t\n",
    "    times.append(t2)\n",
    "    if t2 > 0:\n",
    "        pass\n",
    "        #print(best_par, f\"{t2:.20f} s\")\n",
    "\n",
    "sum(times)/len(times) * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "for i in range(1000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    prev_action = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        #print(state_next, action)\n",
    "        if action == 0:\n",
    "            action=1\n",
    "        else:\n",
    "            action=0\n",
    "\n",
    "        # check position\n",
    "        if state_next[0] < -0.02 and state_next [2]>0.1 and state_next[1]<-0.9:\n",
    "            action=1\n",
    "        elif state_next[0] > 0.02 and state_next [2]<-0.1:\n",
    "            action=0\n",
    "        \n",
    "        if terminal:\n",
    "            print(state_next, action)\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "\n",
    "np.mean(steps), np.sort(steps)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_rand = []\n",
    "X = {}\n",
    "y = []\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    step = 0\n",
    "    X[i] = []\n",
    "\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        action = random.randrange(2)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "        X[i].append(list(state_next))\n",
    "    steps_rand.append(step)\n",
    "    \n",
    "np.mean(steps_rand), np.max(steps_rand), np.sort(steps_rand)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X[i] for marg in list(np.argsort(steps_rand)[-100:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB MultiOutput regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost test\n",
    "import argparse\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def plot_predt(y: np.ndarray, y_predt: np.ndarray, name: str) -> None:\n",
    "    s = 25\n",
    "    plt.scatter(y[:, 0], y[:, 1], c=\"navy\", s=s, edgecolor=\"black\", label=\"data\")\n",
    "    plt.scatter(\n",
    "        y_predt[:, 0], y_predt[:, 1], c=\"cornflowerblue\", s=s, edgecolor=\"black\", label='prediction'\n",
    "    )\n",
    "    plt.xlim([-1, 2])\n",
    "    plt.ylim([-1, 2])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gen_circle() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"Generate a sample dataset that y is a 2 dim circle.\"\n",
    "    rng = np.random.RandomState(1994)\n",
    "    X = 200 * rng.rand(10000, 1) - 100\n",
    "    y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T\n",
    "    y[::5, :] += 0.5 - rng.rand(10000//5, 2)\n",
    "    y = y - y.min()\n",
    "    y = y / y.max()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def rmse_model(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=128)\n",
    "\n",
    "    batch_size = 1000\n",
    "    first_fit = True\n",
    "    for b in range(len(X)//batch_size): #batch size\n",
    "        Xp, yp = X[b*batch_size:(b+1)*batch_size],  y[b*batch_size:(b+1)*batch_size]\n",
    "        if first_fit:\n",
    "            reg.fit(Xp, yp)\n",
    "            first_fit=False\n",
    "        else:\n",
    "            reg = reg.fit(Xp, yp, xgb_model=reg.get_booster())\n",
    "            y_predt = reg.predict(Xp)\n",
    "            print(mean_absolute_error(yp, y_predt))\n",
    "            # plt.plot(Xp)\n",
    "            # plt.show()\n",
    "            # plot_predt(yp, y_predt, 'multi')\n",
    "\n",
    "    #plot_predt(yp, yp, \"multi\")\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")\n",
    "\n",
    "\n",
    "def rmse_model_batch(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=64)\n",
    "    reg.fit(X, y,)# eval_set=[(X, y)])\n",
    "\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_model(True)\n",
    "rmse_model_batch(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "929ea3a73902e04b651b50d7e8bff86e69e28c3f97df2b308a538a481df81bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
