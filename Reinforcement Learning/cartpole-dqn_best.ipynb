{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 2_000\n",
    "RANDOM_RUNS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.05\n",
    "EXPLORATION_DECAY = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.run_memory = []\n",
    "\n",
    "        # load dataset if exist\n",
    "        if os.path.exists(\"datasets\\\\best_memory_dqn.pkl\"):\n",
    "            with open(\"datasets\\\\best_memory_dqn.pkl\", 'rb') as file:\n",
    "                print(\"loaded old best memory\")\n",
    "                self.best_memory = pickle.load(file)\n",
    "        else:\n",
    "            self.best_memory = []\n",
    "\n",
    "        if os.path.exists(\"models\\\\model_dqn.pkl\"):\n",
    "            with open(\"models\\\\model_dqn.pkl\", 'rb') as file:\n",
    "                self.model = pickle.load(file)\n",
    "                print('loaded model')\n",
    "            \n",
    "            self.isFit=True\n",
    "            self.exploration_rate=EXPLORATION_MIN*2\n",
    "        else:\n",
    "            self.model = Sequential()\n",
    "            self.model.add(Dense(48, input_shape=(observation_space,), activation=\"relu\"))\n",
    "            self.model.add(Dense(24, activation=\"relu\"))\n",
    "            self.model.add(Dense(self.action_space, activation=\"linear\"))\n",
    "            self.model.compile(loss=\"mse\", optimizer=Adam(learning_rate=LEARNING_RATE))\n",
    "            self.isFit = False\n",
    "            self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "    def short_remember(self, state, action, reward, next_state, done):\n",
    "        self.run_memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "    def long_remember(self, step):\n",
    "        self.best_memory.append((self.run_memory.copy(), step))\n",
    "        self.run_memory.clear()\n",
    "        # print(len(self.run_memory), len(self.best_memory), MEMORY_SIZE)\n",
    "        \n",
    "        if len(self.best_memory) > MEMORY_SIZE:\n",
    "            # print(len(self.run_memory), len(self.best_memory))\n",
    "            self.best_memory = sorted(self.best_memory, key=lambda x: x[1])\n",
    "            self.best_memory = self.best_memory[-MEMORY_SIZE:]\n",
    "            return True\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            # print(\"Random\")\n",
    "            return random.randrange(self.action_space)\n",
    "        if self.isFit == True:\n",
    "            # print(\"Predict\")\n",
    "            q_values = self.model.predict(state, verbose=0)\n",
    "        else:\n",
    "            q_values = np.zeros(self.action_space).reshape(1, -1)\n",
    "            \n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "\n",
    "    def experience_replay(self):\n",
    "        # print(\"Experience replay\")\n",
    "        if len(self.best_memory) < BATCH_SIZE:\n",
    "            return\n",
    "    \n",
    "        batch = self.best_memory[-BATCH_SIZE//2:] + random.sample(self.best_memory, BATCH_SIZE//2)\n",
    "        all_frames = np.array(sum([b for b, step in batch], []), dtype='object')\n",
    "        len_frames = all_frames.shape[0]\n",
    "        # print(\"Total frames to train\", len_frames)\n",
    "        # X_v = np.empty((len_frames, 4))\n",
    "        # y_v = np.empty((len_frames, 2))\n",
    "\n",
    "        rewards = all_frames[:, 2]\n",
    "        states_next = np.concatenate(all_frames[:, 3])\n",
    "        terminals = all_frames[:, 4]\n",
    "        states = np.concatenate(all_frames[:, 0])\n",
    "        actions = all_frames[:, 1].astype('int8')\n",
    "\n",
    "        # already fit model\n",
    "        if self.isFit:\n",
    "            q_values = self.model.predict(states, verbose=0).astype('float')\n",
    "            q_updates = np.where(terminals, rewards, (rewards + GAMMA * np.amax(self.model.predict(states_next, verbose=0), axis=1)).astype('float'))\n",
    "        else:\n",
    "            q_values = np.zeros((len_frames, self.action_space))\n",
    "            q_updates = rewards\n",
    "            \n",
    "        q_v0 = np.where(actions==0, q_updates, q_values[:, 0]).reshape(-1,1)\n",
    "        #q_v0 = np.where(terminal, rewards, q_v0).reshape(-1, 1) # q_values[0, 1], q_values[1,0], q_values[2, 1]\n",
    "        q_v1 = np.where(actions==1, q_updates, q_values[:, 1]).reshape(-1,1)\n",
    "        # q_v1 = np.where(terminal, rewards, q_v1).reshape(-1, 1)# q_values[0, 1], q_values[1,0], q_values[2, 1]\n",
    "\n",
    "        y_v = np.concatenate((q_v0, q_v1), axis=1)\n",
    "        X_v = states\n",
    "        \n",
    "        # print(reward)\n",
    "        # print(\" Training \".center(80, '*'))\n",
    "        # print(X)\n",
    "        # print(y)\n",
    "        self.model.fit(X_v.astype('float64'), y_v.astype('float64'), epochs=5, verbose=0)\n",
    "        self.isFit = True\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded old best memory\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://00ece0cb-9938-46bc-8262-c9e8a0c8329e/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-dqn_best.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m observation_space \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m action_space \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39maction_space\u001b[39m.\u001b[39mn\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dqn_solver \u001b[39m=\u001b[39m DQNSolver(observation_space, action_space)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m batch \u001b[39m=\u001b[39m dqn_solver\u001b[39m.\u001b[39mbest_memory[\u001b[39m-\u001b[39mBATCH_SIZE\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m:] \u001b[39m+\u001b[39m random\u001b[39m.\u001b[39msample(dqn_solver\u001b[39m.\u001b[39mbest_memory, BATCH_SIZE\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m all_frames \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(\u001b[39msum\u001b[39m([b \u001b[39mfor\u001b[39;00m b, step \u001b[39min\u001b[39;00m batch], []), dtype\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-dqn_best.ipynb Cell 3\u001b[0m in \u001b[0;36mDQNSolver.__init__\u001b[1;34m(self, observation_space, action_space)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmodel_dqn.pkl\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmodels\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mmodel_dqn.pkl\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(file)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mloaded model\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misFit\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\keras\\saving\\pickle_utils.py:47\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[1;34m(serialized_model)\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mGFile(dest_path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     46\u001b[0m                 f\u001b[39m.\u001b[39mwrite(archive\u001b[39m.\u001b[39mextractfile(name)\u001b[39m.\u001b[39mread())\n\u001b[1;32m---> 47\u001b[0m model \u001b[39m=\u001b[39m save_module\u001b[39m.\u001b[39;49mload_model(temp_dir)\n\u001b[0;32m     48\u001b[0m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mrmtree(temp_dir)\n\u001b[0;32m     49\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:933\u001b[0m, in \u001b[0;36mload_partial\u001b[1;34m(export_dir, filters, tags, options)\u001b[0m\n\u001b[0;32m    930\u001b[0m   loader \u001b[39m=\u001b[39m Loader(object_graph_proto, saved_model_proto, export_dir,\n\u001b[0;32m    931\u001b[0m                   ckpt_options, options, filters)\n\u001b[0;32m    932\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mNotFoundError \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 933\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m    934\u001b[0m       \u001b[39mstr\u001b[39m(err) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m You may be trying to load on a different device \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    935\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mfrom the computational device. Consider setting the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39m`experimental_io_device` option in `tf.saved_model.LoadOptions` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    937\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mto the io_device such as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m/job:localhost\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    938\u001b[0m root \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mget(\u001b[39m0\u001b[39m)\n\u001b[0;32m    939\u001b[0m root\u001b[39m.\u001b[39mgraph_debug_info \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39madjust_debug_info_func_names(debug_info)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ram://00ece0cb-9938-46bc-8262-c9e8a0c8329e/variables/variables\n You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'."
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"models\\\\model_lightGBM.pkl\"):\n",
    "    with open(\"models\\\\model_lightGBM.pkl\", 'rb') as file:\n",
    "        lbm = pickle.load(file)\n",
    "        # print('loaded model')\n",
    "        \n",
    "env = gym.make(ENV_NAME)\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "dqn_solver = DQNSolver(observation_space, action_space)\n",
    "\n",
    "batch = dqn_solver.best_memory[-BATCH_SIZE//2:] + random.sample(dqn_solver.best_memory, BATCH_SIZE//2)\n",
    "all_frames = np.array(sum([b for b, step in batch], []), dtype='object')\n",
    "len_frames = all_frames.shape[0]\n",
    "\n",
    "rewards = all_frames[:, 2]\n",
    "states_next = np.concatenate(all_frames[:, 3])\n",
    "terminals = all_frames[:, 4]\n",
    "states = np.concatenate(all_frames[:, 0])\n",
    "actions = all_frames[:, 1].astype('int8')\n",
    "\n",
    "q_values = lbm.predict(states).astype('float')\n",
    "q_updates = np.where(terminals, rewards, (rewards + GAMMA * np.amax(lbm.predict(states_next), axis=1)).astype('float'))\n",
    "      \n",
    "q_v0 = np.where(actions==0, q_updates, q_values[:, 0]).reshape(-1,1)\n",
    "q_v1 = np.where(actions==1, q_updates, q_values[:, 1]).reshape(-1,1)\n",
    "\n",
    "y_v = np.concatenate((q_v0, q_v1), axis=1)\n",
    "X_v = states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3340/3340 [==============================] - 5s 1ms/step - loss: 13.6704\n",
      "Epoch 2/2\n",
      "3340/3340 [==============================] - 4s 1ms/step - loss: 0.6877\n"
     ]
    }
   ],
   "source": [
    "# transfer algorithm on dqn\n",
    "\n",
    "dqn_solver.model.fit(X_v.astype('float64'), y_v.astype('float64'), epochs=2)\n",
    "y_dqn = dqn_solver.model.predict(X_v, verbose=0)\n",
    "dqn_solver.isFit = True\n",
    "dqn_solver.exploration_rate = EXPLORATION_MIN*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5949674229093266, True, 0.1)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_v, y_dqn), dqn_solver.isFit, dqn_solver.exploration_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Epoch 1/20\n",
      "3288/3288 [==============================] - 4s 1ms/step - loss: 0.3659\n",
      "Epoch 2/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3677\n",
      "Epoch 3/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3669\n",
      "Epoch 4/20\n",
      "3288/3288 [==============================] - 6s 2ms/step - loss: 0.3662\n",
      "Epoch 5/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3661\n",
      "Epoch 6/20\n",
      "3288/3288 [==============================] - 5s 2ms/step - loss: 0.3657\n",
      "Epoch 7/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3646\n",
      "Epoch 8/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3654\n",
      "Epoch 9/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3647\n",
      "Epoch 10/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3652\n",
      "Epoch 11/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3662\n",
      "Epoch 12/20\n",
      "3288/3288 [==============================] - 5s 2ms/step - loss: 0.3636\n",
      "Epoch 13/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3644\n",
      "Epoch 14/20\n",
      "3288/3288 [==============================] - 5s 2ms/step - loss: 0.3645\n",
      "Epoch 15/20\n",
      "3288/3288 [==============================] - 5s 2ms/step - loss: 0.3643\n",
      "Epoch 16/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3640\n",
      "Epoch 17/20\n",
      "3288/3288 [==============================] - 6s 2ms/step - loss: 0.3632\n",
      "Epoch 18/20\n",
      "3288/3288 [==============================] - 5s 2ms/step - loss: 0.3630\n",
      "Epoch 19/20\n",
      "3288/3288 [==============================] - 6s 2ms/step - loss: 0.3656\n",
      "Epoch 20/20\n",
      "3288/3288 [==============================] - 5s 1ms/step - loss: 0.3626\n",
      "\n",
      "Run: 100000, exploration: 0.098 | Best memory -> Best: 500, Mean: 327.22, Worst: 236 | Last 100 runs -> Best: 500, Mean: 500.00, Worst: 500\n",
      "####################################################################################################Epoch 1/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3668\n",
      "Epoch 2/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3659\n",
      "Epoch 3/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3651\n",
      "Epoch 4/20\n",
      "3297/3297 [==============================] - 7s 2ms/step - loss: 0.3648\n",
      "Epoch 5/20\n",
      "3297/3297 [==============================] - 7s 2ms/step - loss: 0.3650\n",
      "Epoch 6/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3639\n",
      "Epoch 7/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3630\n",
      "Epoch 8/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3649\n",
      "Epoch 9/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3639\n",
      "Epoch 10/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3636\n",
      "Epoch 11/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3632\n",
      "Epoch 12/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3619\n",
      "Epoch 13/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3631\n",
      "Epoch 14/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3631\n",
      "Epoch 15/20\n",
      "3297/3297 [==============================] - 8s 2ms/step - loss: 0.3627\n",
      "Epoch 16/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3619\n",
      "Epoch 17/20\n",
      "3297/3297 [==============================] - 6s 2ms/step - loss: 0.3630\n",
      "Epoch 18/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3619\n",
      "Epoch 19/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3608\n",
      "Epoch 20/20\n",
      "3297/3297 [==============================] - 5s 2ms/step - loss: 0.3617\n",
      "\n",
      "Run: 100100, exploration: 0.096 | Best memory -> Best: 500, Mean: 328.47, Worst: 237 | Last 100 runs -> Best: 500, Mean: 186.96, Worst: 117\n",
      "###############"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-dqn_best.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# env.render()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m action \u001b[39m=\u001b[39m dqn_solver\u001b[39m.\u001b[39;49mact(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m state_next, reward, terminal, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m reward \u001b[39m=\u001b[39m reward \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m terminal \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39mreward\n",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-dqn_best.ipynb Cell 6\u001b[0m in \u001b[0;36mDQNSolver.act\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39mrandrange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misFit \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m# print(\"Predict\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(state, verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-dqn_best.ipynb#W3sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     q_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py:2249\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   2247\u001b[0m callbacks\u001b[39m.\u001b[39mon_predict_begin()\n\u001b[0;32m   2248\u001b[0m batch_outputs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 2249\u001b[0m \u001b[39mfor\u001b[39;00m _, iterator \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39menumerate_epochs():  \u001b[39m# Single epoch.\u001b[39;00m\n\u001b[0;32m   2250\u001b[0m     \u001b[39mwith\u001b[39;00m data_handler\u001b[39m.\u001b[39mcatch_stop_iteration():\n\u001b[0;32m   2251\u001b[0m         \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m data_handler\u001b[39m.\u001b[39msteps():\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1307\u001b[0m, in \u001b[0;36mDataHandler.enumerate_epochs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1305\u001b[0m \u001b[39m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_truncate_execution_to_epoch():\n\u001b[1;32m-> 1307\u001b[0m     data_iterator \u001b[39m=\u001b[39m \u001b[39miter\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset)\n\u001b[0;32m   1308\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initial_epoch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_epochs):\n\u001b[0;32m   1309\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_insufficient_data:  \u001b[39m# Set by `catch_stop_iteration`.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:499\u001b[0m, in \u001b[0;36mDatasetV2.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly() \u001b[39mor\u001b[39;00m ops\u001b[39m.\u001b[39minside_function():\n\u001b[0;32m    498\u001b[0m   \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variant_tensor):\n\u001b[1;32m--> 499\u001b[0m     \u001b[39mreturn\u001b[39;00m iterator_ops\u001b[39m.\u001b[39;49mOwnedIterator(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    500\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    501\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    502\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39miteration in eager mode or within tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:696\u001b[0m, in \u001b[0;36mOwnedIterator.__init__\u001b[1;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[0;32m    692\u001b[0m   \u001b[39mif\u001b[39;00m (components \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m element_spec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    693\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    694\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    695\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnot be specified.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 696\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_iterator(dataset)\n\u001b[0;32m    698\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_next_call_count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:721\u001b[0m, in \u001b[0;36mOwnedIterator._create_iterator\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mcolocate_with(ds_variant):\n\u001b[0;32m    717\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator_resource \u001b[39m=\u001b[39m (\n\u001b[0;32m    718\u001b[0m       gen_dataset_ops\u001b[39m.\u001b[39manonymous_iterator_v3(\n\u001b[0;32m    719\u001b[0m           output_types\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_types,\n\u001b[0;32m    720\u001b[0m           output_shapes\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_output_shapes))\n\u001b[1;32m--> 721\u001b[0m   gen_dataset_ops\u001b[39m.\u001b[39;49mmake_iterator(ds_variant, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_iterator_resource)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3408\u001b[0m, in \u001b[0;36mmake_iterator\u001b[1;34m(dataset, iterator, name)\u001b[0m\n\u001b[0;32m   3406\u001b[0m \u001b[39mif\u001b[39;00m tld\u001b[39m.\u001b[39mis_eager:\n\u001b[0;32m   3407\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3408\u001b[0m     _result \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_FastPathExecute(\n\u001b[0;32m   3409\u001b[0m       _ctx, \u001b[39m\"\u001b[39;49m\u001b[39mMakeIterator\u001b[39;49m\u001b[39m\"\u001b[39;49m, name, dataset, iterator)\n\u001b[0;32m   3410\u001b[0m     \u001b[39mreturn\u001b[39;00m _result\n\u001b[0;32m   3411\u001b[0m   \u001b[39mexcept\u001b[39;00m _core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%prun \n",
    "# env = gym.make(ENV_NAME)\n",
    "# observation_space = env.observation_space.shape[0]\n",
    "# action_space = env.action_space.n\n",
    "#dqn_solver = LightQSolver(observation_space, action_space)\n",
    "run = RANDOM_RUNS-1\n",
    "steps = []\n",
    "\n",
    "while True:\n",
    "    run += 1\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, observation_space])\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        # env.render()\n",
    "        action = dqn_solver.act(state)\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        reward = reward if not terminal else -reward\n",
    "        state_next = np.reshape(state_next, [1, observation_space])\n",
    "        dqn_solver.short_remember(state, action, reward, state_next, terminal)\n",
    "        state = state_next\n",
    "        if terminal: \n",
    "            print(\"#\", end='')\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "    dqn_solver.long_remember(step)\n",
    "\n",
    "    if run % 100 == 0 and run >= RANDOM_RUNS:\n",
    "        dqn_solver.experience_replay()\n",
    "\n",
    "        print(\"\\nRun: \" + str(run) + \", exploration: \" + str(round(dqn_solver.exploration_rate,3)) + #\", last score: \" + str(step) + \n",
    "            f\" | Best memory -> Best: {dqn_solver.best_memory[-1][-1]}, Mean: {np.mean([x[1] for x in dqn_solver.best_memory]):.2f}, Worst: {dqn_solver.best_memory[0][-1]}\", \n",
    "            f\"| Last 100 runs -> Best: {max(steps)}, Mean: {np.mean(steps):.2f}, Worst: {min(steps)}\")\n",
    "        \n",
    "        steps.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BufferedWriter name='models\\\\model_dqn.pkl'> <keras.engine.sequential.Sequential object at 0x0000023BE29168E0>\n"
     ]
    }
   ],
   "source": [
    "# [print(b[0][0], x) for b, x in dqn_solver.best_memory];\n",
    "# # save dataset\n",
    "# with open(\"datasets\\\\best_memory_dqn.pkl\", 'wb') as file:\n",
    "#     print(file)\n",
    "#     pickle.dump(dqn_solver.best_memory, file)\n",
    "\n",
    "with open(\"models\\\\model_dqn.pkl\", 'wb') as file:\n",
    "    print(file, dqn_solver.model)\n",
    "    dqn_solver.model.save(\"models\\\\model_dqn.hdf5\")\n",
    "\n",
    "# # previous method\n",
    "# X = np.empty((len_frames, 4))\n",
    "# y = np.empty((len_frames, 2))\n",
    "# step_cntr = 0\n",
    "\n",
    "# for b, step in batch:\n",
    "#     for i, (state, action, reward, state_next, terminal) in enumerate(b):\n",
    "#         #print(i+step_cntr, end=\",\")\n",
    "#         q_update = reward\n",
    "#         if not terminal:\n",
    "#             if dqn_solver.isFit:\n",
    "#                 q_update = (reward + GAMMA * np.amax(dqn_solver.model.predict(state_next)[0]))\n",
    "#                 # print(self.model.predict(state_next))\n",
    "#             else:\n",
    "#                 q_update = reward\n",
    "#         if dqn_solver.isFit:\n",
    "#             q_values = dqn_solver.model.predict(state)\n",
    "#         else:\n",
    "#             q_values = np.zeros(dqn_solver.action_space).reshape(1, -1)\n",
    "            \n",
    "#         q_values[0][action] = q_update\n",
    "\n",
    "#         X[i+step_cntr] = state[0]\n",
    "#         y[i+step_cntr] = q_values[0]\n",
    "                    \n",
    "#     step_cntr += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [[\"ok\", 1], [\"?\", 3]]\n",
    "t.append([\"va\", 1])\n",
    "t.append([\"come\", 3])\n",
    "\n",
    "sorted(t, key=lambda x: x[1]), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X[:] == X_v[:]).all(), (y[:] == y_v[:]).all(), y_v[499], y[499], X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"(Best: {dqn_solver.best_memory[-1][-1]}, Worst: {dqn_solver.best_memory[0][-1]})\")\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# # print([x[1] for x in sorted(dqn_solver.best_memory, key=lambda x: x[1])])\n",
    "# if len(dqn_solver.best_memory) > MEMORY_SIZE:\n",
    "#     # print(len(dqn_solver.run_memory), len(dqn_solver.best_memory))\n",
    "#     dqn_solver.best_memory = sorted(dqn_solver.best_memory, key=lambda x: x[1])\n",
    "#     dqn_solver.best_memory = dqn_solver.best_memory[-MEMORY_SIZE:]\n",
    "    \n",
    "# print(f\"(Best: {dqn_solver.best_memory[-1][-1]}, Worst: {dqn_solver.best_memory[0][-1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "step_counter = 0\n",
    "for bm in dqn_solver.best_memory[-100:]:\n",
    "    for i,(state, action, reward, state_next, terminal) in enumerate(bm[0]):\n",
    "        pass\n",
    "        #print(i+step_counter)\n",
    "    step_counter += bm[1]\n",
    "sum([x[1] for x in dqn_solver.best_memory[-100:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = []\n",
    "best_index = []\n",
    "all_data = deque(maxlen=100)\n",
    "max_len = 100\n",
    "import bisect\n",
    "\n",
    "for i in range(1000):\n",
    "    r = random.randint(0, 100)\n",
    "    all_data.append([r,str(i)])\n",
    "\n",
    "    if len(best_params) < max_len:\n",
    "        best_params.append(r)\n",
    "        if len(best_params) == max_len-1:\n",
    "            best_params = sorted(best_params)\n",
    "\n",
    "    bisect.insort(best_params, r)\n",
    "    best_params = best_params[-max_len:]\n",
    "        # best_index = np.argsort(best_params)[-10:]\n",
    "    \n",
    "        \n",
    "print(type(all_data))\n",
    "print(type(sorted(all_data, key=lambda x: x[1])[:4]))\n",
    "all_data.append(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params.insert(len(np.array(best_params)[(np.array(best_params) < 20)]), 20)\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "def bisect_insert(best_params):\n",
    "    bisect.insort(best_params, 20)\n",
    "    return best_params[-10:]\n",
    "\n",
    "def sorted_insert(best_params):\n",
    "    best_params.append(20)\n",
    "    best_params = sorted(best_params)\n",
    "    return best_params[-10:]\n",
    "\n",
    "def sorted_numpy(best_params, arg):\n",
    "    #print(arg, best_params[best_params<arg])\n",
    "    best_params = np.insert(best_params, len(best_params[best_params<arg]), arg)[-max_len:]\n",
    "    return best_params\n",
    "\n",
    "# %timeit bisect_insert(best_params)\n",
    "# %timeit sorted_numpy(np.array(best_params).copy(), 20)\n",
    "print(sorted_numpy(np.array(best_params).copy(), 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "\n",
    "times = []\n",
    "best_par = np.array(best_params).copy()\n",
    "\n",
    "for i in range(100000):\n",
    "    t = time.time()\n",
    "    best_par = sorted_numpy(best_par, random.randint(70, 95))\n",
    "    t2 = time.time()-t\n",
    "    times.append(t2)\n",
    "    if t2 > 0:\n",
    "        pass\n",
    "        #print(best_par, f\"{t2:.20f} s\")\n",
    "\n",
    "sum(times)/len(times) * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "for i in range(1000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    prev_action = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        #print(state_next, action)\n",
    "        if action == 0:\n",
    "            action=1\n",
    "        else:\n",
    "            action=0\n",
    "\n",
    "        # check position\n",
    "        if state_next[0] < -0.02 and state_next [2]>0.1 and state_next[1]<-0.9:\n",
    "            action=1\n",
    "        elif state_next[0] > 0.02 and state_next [2]<-0.1:\n",
    "            action=0\n",
    "        \n",
    "        if terminal:\n",
    "            print(state_next, action)\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "\n",
    "np.mean(steps), np.sort(steps)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_rand = []\n",
    "X = {}\n",
    "y = []\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    step = 0\n",
    "    X[i] = []\n",
    "\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        action = random.randrange(2)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "        X[i].append(list(state_next))\n",
    "    steps_rand.append(step)\n",
    "    \n",
    "np.mean(steps_rand), np.max(steps_rand), np.sort(steps_rand)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X[i] for marg in list(np.argsort(steps_rand)[-100:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB MultiOutput regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost test\n",
    "import argparse\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def plot_predt(y: np.ndarray, y_predt: np.ndarray, name: str) -> None:\n",
    "    s = 25\n",
    "    plt.scatter(y[:, 0], y[:, 1], c=\"navy\", s=s, edgecolor=\"black\", label=\"data\")\n",
    "    plt.scatter(\n",
    "        y_predt[:, 0], y_predt[:, 1], c=\"cornflowerblue\", s=s, edgecolor=\"black\", label='prediction'\n",
    "    )\n",
    "    plt.xlim([-1, 2])\n",
    "    plt.ylim([-1, 2])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gen_circle() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"Generate a sample dataset that y is a 2 dim circle.\"\n",
    "    rng = np.random.RandomState(1994)\n",
    "    X = 200 * rng.rand(10000, 1) - 100\n",
    "    y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T\n",
    "    y[::5, :] += 0.5 - rng.rand(10000//5, 2)\n",
    "    y = y - y.min()\n",
    "    y = y / y.max()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def rmse_model(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=128)\n",
    "\n",
    "    batch_size = 1000\n",
    "    first_fit = True\n",
    "    for b in range(len(X)//batch_size): #batch size\n",
    "        Xp, yp = X[b*batch_size:(b+1)*batch_size],  y[b*batch_size:(b+1)*batch_size]\n",
    "        if first_fit:\n",
    "            reg.fit(Xp, yp)\n",
    "            first_fit=False\n",
    "        else:\n",
    "            reg = reg.fit(Xp, yp, xgb_model=reg.get_booster())\n",
    "            y_predt = reg.predict(Xp)\n",
    "            print(mean_absolute_error(yp, y_predt))\n",
    "            # plt.plot(Xp)\n",
    "            # plt.show()\n",
    "            # plot_predt(yp, y_predt, 'multi')\n",
    "\n",
    "    #plot_predt(yp, yp, \"multi\")\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")\n",
    "\n",
    "\n",
    "def rmse_model_batch(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=64)\n",
    "    reg.fit(X, y,)# eval_set=[(X, y)])\n",
    "\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_model(True)\n",
    "rmse_model_batch(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "929ea3a73902e04b651b50d7e8bff86e69e28c3f97df2b308a538a481df81bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
