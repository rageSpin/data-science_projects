{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "#from scores.score_logger import ScoreLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 100_000\n",
    "RANDOM_RUNS = 10_000\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.05\n",
    "EXPLORATION_DECAY = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightQSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "        self.best_memory = deque(maxlen=MEMORY_SIZE)\n",
    "\n",
    "        self.model = MultiOutputRegressor(LGBMRegressor(n_estimators=100, n_jobs=-1))\n",
    "        self.isFit = False\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            # print(\"Random\")\n",
    "            return random.randrange(self.action_space)\n",
    "        if self.isFit == True:\n",
    "            # print(\"Predict\")\n",
    "            q_values = self.model.predict(state)\n",
    "        else:\n",
    "            q_values = np.zeros(self.action_space).reshape(1, -1)\n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    def experience_replay(self, steps):\n",
    "        if len(self.memory) >= RANDOM_RUNS and len(steps) % 1000:\n",
    "                print(\"Best memory\", len(self.memory))\n",
    "                self.best_memory.remember(np.array(self.memory)[np.argsort(steps)[-100:]])\n",
    "\n",
    "        if len(self.best_memory) < BATCH_SIZE:\n",
    "            return\n",
    "            \n",
    "        batch = random.sample(self.best_memory, BATCH_SIZE)\n",
    "        print(batch)\n",
    "        X = np.empty((BATCH_SIZE, 4))\n",
    "        y = np.empty((BATCH_SIZE,2))\n",
    "        for i, (state, action, reward, state_next, terminal) in enumerate(batch):\n",
    "            # print(reward)\n",
    "            q_update = reward\n",
    "            if not terminal:\n",
    "                if self.isFit:\n",
    "                    q_update = (reward + GAMMA * np.amax(self.model.predict(state_next)[0]))\n",
    "                    # print(self.model.predict(state_next))\n",
    "                else:\n",
    "                    q_update = reward\n",
    "            if self.isFit:\n",
    "                q_values = self.model.predict(state)\n",
    "            else:\n",
    "                q_values = np.zeros(self.action_space).reshape(1, -1)\n",
    "                \n",
    "            q_values[0][action] = q_update\n",
    "\n",
    "            X[i] = state[0]\n",
    "            y[i] = q_values[0]\n",
    "            \n",
    "        # print(reward)\n",
    "        print(\" Training \".center(80, '*'))\n",
    "        # print(X)\n",
    "        # print(y)\n",
    "        self.model.fit(X, y)\n",
    "        self.isFit = True\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "    \n",
    "class XGBQSolver(LightQSolver):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__(observation_space, action_space)\n",
    "        self.model = XGBRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([87, 88, 89, 89, 92, 92, 95, 96, 98, 100],\n",
       " array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int64))"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = []\n",
    "best_index = []\n",
    "all_data = []\n",
    "max_len = 10\n",
    "for i in range(100):\n",
    "    r = random.randint(0, 100)\n",
    "    best_params.append(r)\n",
    "    all_data.append(r)\n",
    "    if len(best_params) > max_len:\n",
    "       \n",
    "        best_params =  sorted(best_params)[-10:]\n",
    "        best_index = np.argsort(best_params)[-10:]\n",
    "\n",
    "best_params, best_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 14, 29, 34, 36, 41, 48, 72, 80, 93]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reimplement main\n",
    "sorted(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "for i in range(1000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    prev_action = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        #print(state_next, action)\n",
    "        if action == 0:\n",
    "            action=1\n",
    "        else:\n",
    "            action=0\n",
    "\n",
    "        # check position\n",
    "        if state_next[0] < -0.02 and state_next [2]>0.1 and state_next[1]<-0.9:\n",
    "            action=1\n",
    "        elif state_next[0] > 0.02 and state_next [2]<-0.1:\n",
    "            action=0\n",
    "        \n",
    "        if terminal:\n",
    "            print(state_next, action)\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "\n",
    "np.mean(steps), np.sort(steps)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_rand = []\n",
    "X = {}\n",
    "y = []\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    step = 0\n",
    "    X[i] = []\n",
    "\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        action = random.randrange(2)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "        X[i].append(list(state_next))\n",
    "    steps_rand.append(step)\n",
    "    \n",
    "np.mean(steps_rand), np.max(steps_rand), np.sort(steps_rand)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X[i] for marg in list(np.argsort(steps_rand)[-100:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB MultiOutput regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost test\n",
    "import argparse\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def plot_predt(y: np.ndarray, y_predt: np.ndarray, name: str) -> None:\n",
    "    s = 25\n",
    "    plt.scatter(y[:, 0], y[:, 1], c=\"navy\", s=s, edgecolor=\"black\", label=\"data\")\n",
    "    plt.scatter(\n",
    "        y_predt[:, 0], y_predt[:, 1], c=\"cornflowerblue\", s=s, edgecolor=\"black\", label='prediction'\n",
    "    )\n",
    "    plt.xlim([-1, 2])\n",
    "    plt.ylim([-1, 2])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gen_circle() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"Generate a sample dataset that y is a 2 dim circle.\"\n",
    "    rng = np.random.RandomState(1994)\n",
    "    X = 200 * rng.rand(10000, 1) - 100\n",
    "    y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T\n",
    "    y[::5, :] += 0.5 - rng.rand(10000//5, 2)\n",
    "    y = y - y.min()\n",
    "    y = y / y.max()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def rmse_model(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=128)\n",
    "\n",
    "    batch_size = 1000\n",
    "    first_fit = True\n",
    "    for b in range(len(X)//batch_size): #batch size\n",
    "        Xp, yp = X[b*batch_size:(b+1)*batch_size],  y[b*batch_size:(b+1)*batch_size]\n",
    "        if first_fit:\n",
    "            reg.fit(Xp, yp)\n",
    "            first_fit=False\n",
    "        else:\n",
    "            reg = reg.fit(Xp, yp, xgb_model=reg.get_booster())\n",
    "            y_predt = reg.predict(Xp)\n",
    "            print(mean_absolute_error(yp, y_predt))\n",
    "            # plt.plot(Xp)\n",
    "            # plt.show()\n",
    "            # plot_predt(yp, y_predt, 'multi')\n",
    "\n",
    "    #plot_predt(yp, yp, \"multi\")\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")\n",
    "\n",
    "\n",
    "def rmse_model_batch(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=64)\n",
    "    reg.fit(X, y,)# eval_set=[(X, y)])\n",
    "\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_model(True)\n",
    "rmse_model_batch(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "929ea3a73902e04b651b50d7e8bff86e69e28c3f97df2b308a538a481df81bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
