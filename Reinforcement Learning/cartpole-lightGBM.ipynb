{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\__init__.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  _nlv = LooseVersion(_np_version)\n",
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\pandas\\compat\\numpy\\function.py:120: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(__version__) >= LooseVersion(\"1.17.0\"):\n",
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:116: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(version) < minimum_version:\n",
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:116: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if distutils.version.LooseVersion(version) < minimum_version:\n",
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\setuptools\\_distutils\\version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "ENV_NAME = \"CartPole-v1\"\n",
    "\n",
    "GAMMA = 0.95\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "MEMORY_SIZE = 2_000\n",
    "RANDOM_RUNS = 100_000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "EXPLORATION_MAX = 1.0\n",
    "EXPLORATION_MIN = 0.05\n",
    "EXPLORATION_DECAY = 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(\"datasets\\\\best_memory_lightGBM.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightQSolver:\n",
    "\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.run_memory = []\n",
    "\n",
    "        # load dataset if exist\n",
    "        if os.path.exists(\"datasets\\\\best_memory_lightGBM.pkl\"):\n",
    "            with open(\"datasets\\\\best_memory_lightGBM.pkl\", 'rb') as file:\n",
    "                print(\"loaded old best memory\")\n",
    "                self.best_memory = pickle.load(file)\n",
    "        else:\n",
    "            self.best_memory = []\n",
    "\n",
    "        if os.path.exists(\"models\\\\model_lightGBM.pkl\"):\n",
    "            with open(\"models\\\\model_lightGBM.pkl\", 'rb') as file:\n",
    "                self.model = pickle.load(file)\n",
    "                print('loaded model')\n",
    "            \n",
    "            self.isFit=True\n",
    "            self.exploration_rate=EXPLORATION_MIN*2\n",
    "        else:\n",
    "            self.model = MultiOutputRegressor(LGBMRegressor(n_estimators=100, n_jobs=-1))\n",
    "            self.isFit = False\n",
    "            self.exploration_rate = EXPLORATION_MAX\n",
    "\n",
    "    def short_remember(self, state, action, reward, next_state, done):\n",
    "        self.run_memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "\n",
    "    def long_remember(self, step):\n",
    "        self.best_memory.append((self.run_memory.copy(), step))\n",
    "        self.run_memory.clear()\n",
    "        # print(len(self.run_memory), len(self.best_memory), MEMORY_SIZE)\n",
    "        \n",
    "        if len(self.best_memory) > MEMORY_SIZE:\n",
    "            # print(len(self.run_memory), len(self.best_memory))\n",
    "            self.best_memory = sorted(self.best_memory, key=lambda x: x[1])\n",
    "            self.best_memory = self.best_memory[-MEMORY_SIZE:]\n",
    "            return True\n",
    "\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            # print(\"Random\")\n",
    "            return random.randrange(self.action_space)\n",
    "        if self.isFit == True:\n",
    "            # print(\"Predict\")\n",
    "            q_values = self.model.predict(state)\n",
    "        else:\n",
    "            q_values = np.zeros(self.action_space).reshape(1, -1)\n",
    "            \n",
    "        return np.argmax(q_values[0])\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_bactch(data):\n",
    "        batch = []\n",
    "        for b, step in data:\n",
    "            for (state, action, reward, state_next, terminal) in b:\n",
    "                pass\n",
    "\n",
    "    def experience_replay(self):\n",
    "        # print(\"Experience replay\")\n",
    "        if len(self.best_memory) < BATCH_SIZE:\n",
    "            return\n",
    "    \n",
    "        batch = dqn_solver.best_memory[-BATCH_SIZE//2:] + random.sample(dqn_solver.best_memory, BATCH_SIZE//2)\n",
    "        all_frames = np.array(sum([b for b, step in batch], []), dtype='object')\n",
    "        len_frames = all_frames.shape[0]\n",
    "        # print(\"Total frames to train\", len_frames)\n",
    "        # X_v = np.empty((len_frames, 4))\n",
    "        # y_v = np.empty((len_frames, 2))\n",
    "\n",
    "        rewards = all_frames[:, 2]\n",
    "        states_next = np.concatenate(all_frames[:, 3])\n",
    "        terminals = all_frames[:, 4]\n",
    "        states = np.concatenate(all_frames[:, 0])\n",
    "        actions = all_frames[:, 1].astype('int8')\n",
    "\n",
    "        # already fit model\n",
    "        if self.isFit:\n",
    "            q_values = dqn_solver.model.predict(states).astype('float')\n",
    "            q_updates = np.where(terminals, rewards, (rewards + GAMMA * np.amax(dqn_solver.model.predict(states_next), axis=1)).astype('float'))\n",
    "        else:\n",
    "            q_values = np.zeros((len_frames, self.action_space))\n",
    "            q_updates = rewards\n",
    "            \n",
    "        q_v0 = np.where(actions==0, q_updates, q_values[:, 0]).reshape(-1,1)\n",
    "        #q_v0 = np.where(terminal, rewards, q_v0).reshape(-1, 1) # q_values[0, 1], q_values[1,0], q_values[2, 1]\n",
    "        q_v1 = np.where(actions==1, q_updates, q_values[:, 1]).reshape(-1,1)\n",
    "        # q_v1 = np.where(terminal, rewards, q_v1).reshape(-1, 1)# q_values[0, 1], q_values[1,0], q_values[2, 1]\n",
    "\n",
    "        y_v = np.concatenate((q_v0, q_v1), axis=1)\n",
    "        X_v = states\n",
    "        \n",
    "        # print(reward)\n",
    "        # print(\" Training \".center(80, '*'))\n",
    "        # print(X)\n",
    "        # print(y)\n",
    "        self.model.fit(X_v, y_v)\n",
    "        self.isFit = True\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        \n",
    "        \n",
    "class XGBQSolver(LightQSolver):\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super().__init__(observation_space, action_space)\n",
    "        self.model = XGBRegressor(n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded old best memory\n",
      "loaded model\n",
      "#\n",
      "Run: 100000, exploration: 0.098 | Best memory -> Best: 500, Mean: 295.74, Worst: 225 | Last 100 runs -> Best: 183, Mean: 183.00, Worst: 183\n",
      "####################################################################################################\n",
      "Run: 100100, exploration: 0.096 | Best memory -> Best: 500, Mean: 297.19, Worst: 225 | Last 100 runs -> Best: 500, Mean: 215.76, Worst: 79\n",
      "####################################################################################################\n",
      "Run: 100200, exploration: 0.094 | Best memory -> Best: 500, Mean: 300.43, Worst: 227 | Last 100 runs -> Best: 500, Mean: 269.31, Worst: 70\n",
      "####################################################################################################\n",
      "Run: 100300, exploration: 0.092 | Best memory -> Best: 500, Mean: 306.59, Worst: 228 | Last 100 runs -> Best: 500, Mean: 326.78, Worst: 32\n",
      "####################################################################################################\n",
      "Run: 100400, exploration: 0.09 | Best memory -> Best: 500, Mean: 310.34, Worst: 229 | Last 100 runs -> Best: 500, Mean: 272.60, Worst: 78\n",
      "####################################################################################################\n",
      "Run: 100500, exploration: 0.089 | Best memory -> Best: 500, Mean: 312.59, Worst: 230 | Last 100 runs -> Best: 500, Mean: 209.68, Worst: 47\n",
      "####################################################################################################\n",
      "Run: 100600, exploration: 0.087 | Best memory -> Best: 500, Mean: 315.21, Worst: 231 | Last 100 runs -> Best: 500, Mean: 237.76, Worst: 62\n",
      "####################################################################################################\n",
      "Run: 100700, exploration: 0.085 | Best memory -> Best: 500, Mean: 318.47, Worst: 232 | Last 100 runs -> Best: 500, Mean: 264.82, Worst: 56\n",
      "####################################################################################################\n",
      "Run: 100800, exploration: 0.083 | Best memory -> Best: 500, Mean: 323.48, Worst: 234 | Last 100 runs -> Best: 500, Mean: 316.42, Worst: 66\n",
      "####################################################################################################\n",
      "Run: 100900, exploration: 0.082 | Best memory -> Best: 500, Mean: 324.36, Worst: 235 | Last 100 runs -> Best: 500, Mean: 192.79, Worst: 78\n",
      "####################################################################################################\n",
      "Run: 101000, exploration: 0.08 | Best memory -> Best: 500, Mean: 326.54, Worst: 236 | Last 100 runs -> Best: 500, Mean: 251.85, Worst: 93\n",
      "#############################################"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-lightGBM.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m#env.render()\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m action \u001b[39m=\u001b[39m dqn_solver\u001b[39m.\u001b[39;49mact(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m state_next, reward, terminal, info \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mstep(action)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m reward \u001b[39m=\u001b[39m reward \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m terminal \u001b[39melse\u001b[39;00m \u001b[39m-\u001b[39mreward\n",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-lightGBM.ipynb Cell 4\u001b[0m in \u001b[0;36mLightQSolver.act\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39mrandrange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misFit \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39m# print(\"Predict\")\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m     q_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mpredict(state)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#W3sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     q_values \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39maction_space)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py:234\u001b[0m, in \u001b[0;36m_MultiOutputEstimator.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mThe base estimator should implement a predict method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 234\u001b[0m y \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[0;32m    235\u001b[0m     delayed(e\u001b[39m.\u001b[39;49mpredict)(X) \u001b[39mfor\u001b[39;49;00m e \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mestimators_\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39masarray(y)\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:803\u001b[0m, in \u001b[0;36mLGBMModel.predict\u001b[1;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features \u001b[39m!=\u001b[39m n_features:\n\u001b[0;32m    800\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNumber of features of the model must \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    801\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmatch the input. Model n_features_ is \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_features\u001b[39m}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    802\u001b[0m                      \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput n_features is \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 803\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_Booster\u001b[39m.\u001b[39mpredict(X, raw_score\u001b[39m=\u001b[39mraw_score, start_iteration\u001b[39m=\u001b[39mstart_iteration, num_iteration\u001b[39m=\u001b[39mnum_iteration,\n\u001b[0;32m    804\u001b[0m                              pred_leaf\u001b[39m=\u001b[39mpred_leaf, pred_contrib\u001b[39m=\u001b[39mpred_contrib, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:3538\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   3536\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3537\u001b[0m         num_iteration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 3538\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mpredict(data, start_iteration, num_iteration,\n\u001b[0;32m   3539\u001b[0m                          raw_score, pred_leaf, pred_contrib,\n\u001b[0;32m   3540\u001b[0m                          data_has_header, is_reshape)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:848\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    846\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_csc(data, start_iteration, num_iteration, predict_type)\n\u001b[0;32m    847\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m--> 848\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pred_for_np2d(data, start_iteration, num_iteration, predict_type)\n\u001b[0;32m    849\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    850\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:938\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[39mreturn\u001b[39;00m preds, nrow\n\u001b[0;32m    937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_predict(mat, start_iteration, num_iteration, predict_type)\n",
      "File \u001b[1;32mc:\\Users\\stefano.giannini_ama\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:908\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d.<locals>.inner_predict\u001b[1;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length of pre-allocated predict array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    907\u001b[0m out_num_preds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int64(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 908\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterPredictForMat(\n\u001b[0;32m    909\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m    910\u001b[0m     ptr_data,\n\u001b[0;32m    911\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_ptr_data),\n\u001b[0;32m    912\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[0;32m    913\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m    914\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(C_API_IS_ROW_MAJOR),\n\u001b[0;32m    915\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(predict_type),\n\u001b[0;32m    916\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(start_iteration),\n\u001b[0;32m    917\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(num_iteration),\n\u001b[0;32m    918\u001b[0m     c_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_parameter),\n\u001b[0;32m    919\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_preds),\n\u001b[0;32m    920\u001b[0m     preds\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(ctypes\u001b[39m.\u001b[39;49mPOINTER(ctypes\u001b[39m.\u001b[39;49mc_double))))\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m n_preds \u001b[39m!=\u001b[39m out_num_preds\u001b[39m.\u001b[39mvalue:\n\u001b[0;32m    922\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length for predict results\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%prun \n",
    "env = gym.make(ENV_NAME)\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "dqn_solver = LightQSolver(observation_space, action_space)\n",
    "run = RANDOM_RUNS-1\n",
    "steps = []\n",
    "\n",
    "while True:\n",
    "    run += 1\n",
    "    state = env.reset()\n",
    "    state = np.reshape(state, [1, observation_space])\n",
    "    step = 0\n",
    "    while True:\n",
    "        step += 1\n",
    "        #env.render()\n",
    "        action = dqn_solver.act(state)\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        reward = reward if not terminal else -reward\n",
    "        state_next = np.reshape(state_next, [1, observation_space])\n",
    "        dqn_solver.short_remember(state, action, reward, state_next, terminal)\n",
    "        state = state_next\n",
    "        if terminal: \n",
    "            print(\"#\", end='')\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "    dqn_solver.long_remember(step)\n",
    "\n",
    "    if run % 100 == 0 and run >= RANDOM_RUNS:\n",
    "        dqn_solver.experience_replay()\n",
    "\n",
    "        print(\"\\nRun: \" + str(run) + \", exploration: \" + str(round(dqn_solver.exploration_rate,3)) + #\", last score: \" + str(step) + \n",
    "            f\" | Best memory -> Best: {dqn_solver.best_memory[-1][-1]}, Mean: {np.mean([x[1] for x in dqn_solver.best_memory]):.2f}, Worst: {dqn_solver.best_memory[0][-1]}\", \n",
    "            f\"| Last 100 runs -> Best: {max(steps)}, Mean: {np.mean(steps):.2f}, Worst: {min(steps)}\")\n",
    "        \n",
    "        steps.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236\n",
      "236\n",
      "236\n",
      "236\n",
      "236\n",
      "236\n",
      "236\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "237\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "238\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "239\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "240\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "241\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "242\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "243\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "244\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "245\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "246\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "247\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "248\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "249\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "250\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "251\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "252\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "253\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "254\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "256\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "257\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "258\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "259\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "260\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "261\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "262\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "263\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "264\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "265\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "266\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "267\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "268\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "269\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "270\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "271\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "272\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "273\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "274\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "275\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "276\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "277\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "278\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "279\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "281\n",
      "282\n",
      "282\n",
      "282\n",
      "282\n",
      "282\n",
      "282\n",
      "282\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "283\n",
      "284\n",
      "284\n",
      "284\n",
      "284\n",
      "284\n",
      "284\n",
      "284\n",
      "285\n",
      "285\n",
      "285\n",
      "285\n",
      "285\n",
      "285\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "286\n",
      "287\n",
      "287\n",
      "287\n",
      "287\n",
      "287\n",
      "287\n",
      "287\n",
      "287\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "288\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "289\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "290\n",
      "291\n",
      "291\n",
      "291\n",
      "291\n",
      "291\n",
      "291\n",
      "291\n",
      "291\n",
      "292\n",
      "292\n",
      "292\n",
      "292\n",
      "292\n",
      "292\n",
      "292\n",
      "293\n",
      "293\n",
      "293\n",
      "293\n",
      "293\n",
      "293\n",
      "293\n",
      "293\n",
      "293\n",
      "294\n",
      "294\n",
      "294\n",
      "294\n",
      "294\n",
      "294\n",
      "294\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "295\n",
      "296\n",
      "296\n",
      "296\n",
      "296\n",
      "297\n",
      "297\n",
      "297\n",
      "297\n",
      "297\n",
      "297\n",
      "297\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "298\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "299\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "300\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "301\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "302\n",
      "303\n",
      "303\n",
      "303\n",
      "303\n",
      "303\n",
      "304\n",
      "304\n",
      "304\n",
      "304\n",
      "304\n",
      "304\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "305\n",
      "306\n",
      "306\n",
      "306\n",
      "306\n",
      "306\n",
      "306\n",
      "306\n",
      "306\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "307\n",
      "308\n",
      "308\n",
      "308\n",
      "308\n",
      "308\n",
      "308\n",
      "308\n",
      "308\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "309\n",
      "310\n",
      "310\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "311\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "312\n",
      "313\n",
      "313\n",
      "313\n",
      "313\n",
      "313\n",
      "313\n",
      "313\n",
      "314\n",
      "314\n",
      "314\n",
      "314\n",
      "314\n",
      "314\n",
      "315\n",
      "315\n",
      "315\n",
      "315\n",
      "315\n",
      "315\n",
      "315\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "316\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "317\n",
      "318\n",
      "318\n",
      "318\n",
      "318\n",
      "318\n",
      "318\n",
      "319\n",
      "319\n",
      "319\n",
      "319\n",
      "319\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "320\n",
      "321\n",
      "321\n",
      "321\n",
      "321\n",
      "321\n",
      "321\n",
      "321\n",
      "321\n",
      "321\n",
      "322\n",
      "323\n",
      "323\n",
      "323\n",
      "323\n",
      "323\n",
      "323\n",
      "323\n",
      "323\n",
      "323\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "324\n",
      "325\n",
      "325\n",
      "325\n",
      "325\n",
      "325\n",
      "325\n",
      "326\n",
      "326\n",
      "326\n",
      "326\n",
      "326\n",
      "326\n",
      "326\n",
      "326\n",
      "326\n",
      "327\n",
      "327\n",
      "327\n",
      "327\n",
      "327\n",
      "327\n",
      "328\n",
      "328\n",
      "328\n",
      "329\n",
      "329\n",
      "329\n",
      "330\n",
      "330\n",
      "330\n",
      "330\n",
      "331\n",
      "331\n",
      "331\n",
      "331\n",
      "331\n",
      "331\n",
      "331\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "332\n",
      "333\n",
      "333\n",
      "333\n",
      "333\n",
      "333\n",
      "334\n",
      "335\n",
      "335\n",
      "335\n",
      "335\n",
      "336\n",
      "336\n",
      "337\n",
      "338\n",
      "338\n",
      "338\n",
      "338\n",
      "339\n",
      "339\n",
      "339\n",
      "340\n",
      "340\n",
      "340\n",
      "340\n",
      "340\n",
      "341\n",
      "341\n",
      "341\n",
      "341\n",
      "342\n",
      "344\n",
      "344\n",
      "344\n",
      "345\n",
      "345\n",
      "346\n",
      "346\n",
      "346\n",
      "347\n",
      "347\n",
      "347\n",
      "347\n",
      "348\n",
      "348\n",
      "348\n",
      "348\n",
      "348\n",
      "348\n",
      "348\n",
      "348\n",
      "349\n",
      "349\n",
      "350\n",
      "350\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "351\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "352\n",
      "353\n",
      "353\n",
      "353\n",
      "353\n",
      "353\n",
      "353\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "354\n",
      "355\n",
      "355\n",
      "355\n",
      "355\n",
      "355\n",
      "356\n",
      "356\n",
      "357\n",
      "357\n",
      "357\n",
      "358\n",
      "358\n",
      "358\n",
      "358\n",
      "359\n",
      "359\n",
      "359\n",
      "359\n",
      "359\n",
      "359\n",
      "359\n",
      "359\n",
      "359\n",
      "360\n",
      "360\n",
      "361\n",
      "361\n",
      "361\n",
      "362\n",
      "362\n",
      "362\n",
      "363\n",
      "363\n",
      "363\n",
      "363\n",
      "364\n",
      "364\n",
      "364\n",
      "364\n",
      "364\n",
      "365\n",
      "365\n",
      "365\n",
      "365\n",
      "366\n",
      "366\n",
      "366\n",
      "366\n",
      "367\n",
      "367\n",
      "368\n",
      "368\n",
      "368\n",
      "370\n",
      "370\n",
      "370\n",
      "370\n",
      "370\n",
      "371\n",
      "371\n",
      "372\n",
      "372\n",
      "372\n",
      "372\n",
      "372\n",
      "372\n",
      "373\n",
      "373\n",
      "373\n",
      "373\n",
      "373\n",
      "374\n",
      "374\n",
      "374\n",
      "375\n",
      "375\n",
      "375\n",
      "375\n",
      "375\n",
      "375\n",
      "376\n",
      "376\n",
      "376\n",
      "377\n",
      "377\n",
      "377\n",
      "377\n",
      "377\n",
      "377\n",
      "378\n",
      "378\n",
      "379\n",
      "379\n",
      "379\n",
      "379\n",
      "380\n",
      "380\n",
      "380\n",
      "381\n",
      "381\n",
      "381\n",
      "382\n",
      "382\n",
      "382\n",
      "382\n",
      "383\n",
      "383\n",
      "383\n",
      "383\n",
      "384\n",
      "384\n",
      "384\n",
      "384\n",
      "385\n",
      "385\n",
      "385\n",
      "385\n",
      "386\n",
      "386\n",
      "387\n",
      "388\n",
      "388\n",
      "389\n",
      "390\n",
      "390\n",
      "390\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "394\n",
      "394\n",
      "394\n",
      "394\n",
      "394\n",
      "395\n",
      "395\n",
      "395\n",
      "395\n",
      "396\n",
      "396\n",
      "396\n",
      "397\n",
      "397\n",
      "397\n",
      "398\n",
      "398\n",
      "398\n",
      "399\n",
      "400\n",
      "400\n",
      "402\n",
      "402\n",
      "403\n",
      "403\n",
      "404\n",
      "404\n",
      "405\n",
      "405\n",
      "405\n",
      "405\n",
      "406\n",
      "406\n",
      "406\n",
      "407\n",
      "407\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "408\n",
      "409\n",
      "409\n",
      "410\n",
      "410\n",
      "410\n",
      "411\n",
      "411\n",
      "411\n",
      "412\n",
      "412\n",
      "413\n",
      "413\n",
      "414\n",
      "414\n",
      "414\n",
      "415\n",
      "415\n",
      "415\n",
      "415\n",
      "416\n",
      "416\n",
      "416\n",
      "417\n",
      "417\n",
      "417\n",
      "418\n",
      "418\n",
      "419\n",
      "419\n",
      "419\n",
      "420\n",
      "420\n",
      "422\n",
      "422\n",
      "423\n",
      "423\n",
      "424\n",
      "425\n",
      "425\n",
      "426\n",
      "427\n",
      "427\n",
      "428\n",
      "428\n",
      "428\n",
      "428\n",
      "428\n",
      "429\n",
      "430\n",
      "430\n",
      "430\n",
      "430\n",
      "432\n",
      "432\n",
      "433\n",
      "433\n",
      "435\n",
      "435\n",
      "435\n",
      "435\n",
      "435\n",
      "435\n",
      "436\n",
      "438\n",
      "439\n",
      "440\n",
      "442\n",
      "442\n",
      "442\n",
      "442\n",
      "442\n",
      "442\n",
      "443\n",
      "445\n",
      "445\n",
      "446\n",
      "446\n",
      "447\n",
      "447\n",
      "448\n",
      "448\n",
      "449\n",
      "449\n",
      "450\n",
      "452\n",
      "453\n",
      "453\n",
      "454\n",
      "455\n",
      "455\n",
      "455\n",
      "457\n",
      "457\n",
      "457\n",
      "458\n",
      "458\n",
      "458\n",
      "458\n",
      "459\n",
      "459\n",
      "460\n",
      "461\n",
      "461\n",
      "462\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "463\n",
      "464\n",
      "464\n",
      "466\n",
      "466\n",
      "466\n",
      "467\n",
      "468\n",
      "468\n",
      "468\n",
      "469\n",
      "469\n",
      "470\n",
      "471\n",
      "471\n",
      "471\n",
      "472\n",
      "473\n",
      "473\n",
      "474\n",
      "475\n",
      "475\n",
      "475\n",
      "476\n",
      "476\n",
      "476\n",
      "476\n",
      "478\n",
      "479\n",
      "479\n",
      "480\n",
      "483\n",
      "483\n",
      "485\n",
      "485\n",
      "486\n",
      "486\n",
      "486\n",
      "486\n",
      "487\n",
      "487\n",
      "489\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "495\n",
      "496\n",
      "496\n",
      "496\n",
      "498\n",
      "498\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "[print(x) for b, x in dqn_solver.best_memory];\n",
    "# import pickle\n",
    "\n",
    "# # save dataset\n",
    "# with open(\"datasets\\\\best_memory_lightGBM.pkl\", 'wb') as file:\n",
    "#     print(file)\n",
    "#     pickle.dump(dqn_solver.best_memory, file)\n",
    "\n",
    "# with open(\"models\\\\model_lightGBM.pkl\", 'wb') as file:\n",
    "#     print(file, dqn_solver.model)\n",
    "#     pickle.dump(dqn_solver.model, file)\n",
    "\n",
    "# # previous method\n",
    "# X = np.empty((len_frames, 4))\n",
    "# y = np.empty((len_frames, 2))\n",
    "# step_cntr = 0\n",
    "\n",
    "# for b, step in batch:\n",
    "#     for i, (state, action, reward, state_next, terminal) in enumerate(b):\n",
    "#         #print(i+step_cntr, end=\",\")\n",
    "#         q_update = reward\n",
    "#         if not terminal:\n",
    "#             if dqn_solver.isFit:\n",
    "#                 q_update = (reward + GAMMA * np.amax(dqn_solver.model.predict(state_next)[0]))\n",
    "#                 # print(self.model.predict(state_next))\n",
    "#             else:\n",
    "#                 q_update = reward\n",
    "#         if dqn_solver.isFit:\n",
    "#             q_values = dqn_solver.model.predict(state)\n",
    "#         else:\n",
    "#             q_values = np.zeros(dqn_solver.action_space).reshape(1, -1)\n",
    "            \n",
    "#         q_values[0][action] = q_update\n",
    "\n",
    "#         X[i+step_cntr] = state[0]\n",
    "#         y[i+step_cntr] = q_values[0]\n",
    "                    \n",
    "#     step_cntr += step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " True,\n",
       " array([-1.0, 19.518925660280548], dtype=object),\n",
       " array([-1.        , 19.51892566]),\n",
       " array([[-0.01177179,  0.01539265,  0.02065057, -0.02941784],\n",
       "        [-0.01146393,  0.21021247,  0.02006221, -0.31551442],\n",
       "        [-0.00725968,  0.01481057,  0.01375192, -0.01657267],\n",
       "        ...,\n",
       "        [-2.37354469, -0.36992678, -0.07391655, -0.26001579],\n",
       "        [-2.3809433 , -0.56391996, -0.07911687,  0.00846776],\n",
       "        [-2.39222169, -0.75782335, -0.07894751,  0.27517694]]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[:] == X_v[:]).all(), (y[:] == y_v[:]).all(), y_v[499], y[499], X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01177179,  0.01539265,  0.02065057, -0.02941784],\n",
       "       [-0.01146393,  0.21021247,  0.02006221, -0.31551442],\n",
       "       [-0.00725968,  0.01481057,  0.01375192, -0.01657267],\n",
       "       ...,\n",
       "       [-2.37354469, -0.36992678, -0.07391655, -0.26001579],\n",
       "       [-2.3809433 , -0.56391996, -0.07911687,  0.00846776],\n",
       "       [-2.39222169, -0.75782335, -0.07894751,  0.27517694]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stefano.giannini_ama\\Documents\\Python\\Learn\\data-science_projects\\Reinforcement Learning\\cartpole-lightGBM.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stefano.giannini_ama/Documents/Python/Learn/data-science_projects/Reinforcement%20Learning/cartpole-lightGBM.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39msoftmax()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"(Best: {dqn_solver.best_memory[-1][-1]}, Worst: {dqn_solver.best_memory[0][-1]})\")\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# dqn_solver.best_memory.append((\"test\", 11))\n",
    "# # print([x[1] for x in sorted(dqn_solver.best_memory, key=lambda x: x[1])])\n",
    "# if len(dqn_solver.best_memory) > MEMORY_SIZE:\n",
    "#     # print(len(dqn_solver.run_memory), len(dqn_solver.best_memory))\n",
    "#     dqn_solver.best_memory = sorted(dqn_solver.best_memory, key=lambda x: x[1])\n",
    "#     dqn_solver.best_memory = dqn_solver.best_memory[-MEMORY_SIZE:]\n",
    "    \n",
    "# print(f\"(Best: {dqn_solver.best_memory[-1][-1]}, Worst: {dqn_solver.best_memory[0][-1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = []\n",
    "step_counter = 0\n",
    "for bm in dqn_solver.best_memory[-100:]:\n",
    "    for i,(state, action, reward, state_next, terminal) in enumerate(bm[0]):\n",
    "        pass\n",
    "        #print(i+step_counter)\n",
    "    step_counter += bm[1]\n",
    "sum([x[1] for x in dqn_solver.best_memory[-100:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'collections.deque'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "best_params = []\n",
    "best_index = []\n",
    "all_data = deque(maxlen=100)\n",
    "max_len = 100\n",
    "import bisect\n",
    "\n",
    "for i in range(1000):\n",
    "    r = random.randint(0, 100)\n",
    "    all_data.append([r,str(i)])\n",
    "\n",
    "    if len(best_params) < max_len:\n",
    "        best_params.append(r)\n",
    "        if len(best_params) == max_len-1:\n",
    "            best_params = sorted(best_params)\n",
    "\n",
    "    bisect.insort(best_params, r)\n",
    "    best_params = best_params[-max_len:]\n",
    "        # best_index = np.argsort(best_params)[-10:]\n",
    "    \n",
    "        \n",
    "print(type(all_data))\n",
    "print(type(sorted(all_data, key=lambda x: x[1])[:4]))\n",
    "all_data.append(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 91, 91, 91, 92, 92, 92, 92, 92, 92, 92, 92, 92, 92, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 93, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 94, 95, 95, 95, 95, 95, 95, 95, 95, 95, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 96, 97, 97, 97, 97, 97, 97, 97, 98, 98, 98, 98, 98, 98, 98, 98, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 99, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "best_params.insert(len(np.array(best_params)[(np.array(best_params) < 20)]), 20)\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100 100 100 100 100 100 100 100 100 100]\n",
      "[ 95 100 100 100 100 100 100 100 100 100 100]\n"
     ]
    }
   ],
   "source": [
    "import bisect\n",
    "\n",
    "print(best_params)\n",
    "\n",
    "def bisect_insert(best_params):\n",
    "    bisect.insort(best_params, 20)\n",
    "    return best_params[-10:]\n",
    "\n",
    "def sorted_insert(best_params):\n",
    "    best_params.append(20)\n",
    "    best_params = sorted(best_params)\n",
    "    return best_params[-10:]\n",
    "\n",
    "def sorted_numpy(best_params, arg):\n",
    "    #print(arg, best_params[best_params<arg])\n",
    "    best_params = np.insert(best_params, len(best_params[best_params<arg]), arg)[-max_len:]\n",
    "    return best_params\n",
    "\n",
    "# %timeit bisect_insert(best_params)\n",
    "# %timeit sorted_numpy(np.array(best_params).copy(), 20)\n",
    "print(sorted_numpy(np.array(best_params).copy(), 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.332043647766113"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "times = []\n",
    "best_par = np.array(best_params).copy()\n",
    "\n",
    "for i in range(100000):\n",
    "    t = time.time()\n",
    "    best_par = sorted_numpy(best_par, random.randint(70, 95))\n",
    "    t2 = time.time()-t\n",
    "    times.append(t2)\n",
    "    if t2 > 0:\n",
    "        pass\n",
    "        #print(best_par, f\"{t2:.20f} s\")\n",
    "\n",
    "sum(times)/len(times) * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "for i in range(1000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    prev_action = 0\n",
    "    step = 0\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        #print(state_next, action)\n",
    "        if action == 0:\n",
    "            action=1\n",
    "        else:\n",
    "            action=0\n",
    "\n",
    "        # check position\n",
    "        if state_next[0] < -0.02 and state_next [2]>0.1 and state_next[1]<-0.9:\n",
    "            action=1\n",
    "        elif state_next[0] > 0.02 and state_next [2]<-0.1:\n",
    "            action=0\n",
    "        \n",
    "        if terminal:\n",
    "            print(state_next, action)\n",
    "            break\n",
    "\n",
    "    steps.append(step)\n",
    "\n",
    "np.mean(steps), np.sort(steps)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_rand = []\n",
    "X = {}\n",
    "y = []\n",
    "for i in range(10000):\n",
    "    env.reset()\n",
    "    action = 0\n",
    "    step = 0\n",
    "    X[i] = []\n",
    "\n",
    "    while True:\n",
    "        state_next, reward, terminal, info = env.step(action)\n",
    "        step+=1\n",
    "        action = random.randrange(2)\n",
    "        \n",
    "        if terminal:\n",
    "            break\n",
    "\n",
    "        X[i].append(list(state_next))\n",
    "    steps_rand.append(step)\n",
    "    \n",
    "np.mean(steps_rand), np.max(steps_rand), np.sort(steps_rand)[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[X[i] for marg in list(np.argsort(steps_rand)[-100:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB MultiOutput regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost test\n",
    "import argparse\n",
    "from typing import Dict, Tuple, List\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import xgboost as xgb\n",
    "\n",
    "def plot_predt(y: np.ndarray, y_predt: np.ndarray, name: str) -> None:\n",
    "    s = 25\n",
    "    plt.scatter(y[:, 0], y[:, 1], c=\"navy\", s=s, edgecolor=\"black\", label=\"data\")\n",
    "    plt.scatter(\n",
    "        y_predt[:, 0], y_predt[:, 1], c=\"cornflowerblue\", s=s, edgecolor=\"black\", label='prediction'\n",
    "    )\n",
    "    plt.xlim([-1, 2])\n",
    "    plt.ylim([-1, 2])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def gen_circle() -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"Generate a sample dataset that y is a 2 dim circle.\"\n",
    "    rng = np.random.RandomState(1994)\n",
    "    X = 200 * rng.rand(10000, 1) - 100\n",
    "    y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T\n",
    "    y[::5, :] += 0.5 - rng.rand(10000//5, 2)\n",
    "    y = y - y.min()\n",
    "    y = y / y.max()\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def rmse_model(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=128)\n",
    "\n",
    "    batch_size = 1000\n",
    "    first_fit = True\n",
    "    for b in range(len(X)//batch_size): #batch size\n",
    "        Xp, yp = X[b*batch_size:(b+1)*batch_size],  y[b*batch_size:(b+1)*batch_size]\n",
    "        if first_fit:\n",
    "            reg.fit(Xp, yp)\n",
    "            first_fit=False\n",
    "        else:\n",
    "            reg = reg.fit(Xp, yp, xgb_model=reg.get_booster())\n",
    "            y_predt = reg.predict(Xp)\n",
    "            print(mean_absolute_error(yp, y_predt))\n",
    "            # plt.plot(Xp)\n",
    "            # plt.show()\n",
    "            # plot_predt(yp, y_predt, 'multi')\n",
    "\n",
    "    #plot_predt(yp, yp, \"multi\")\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")\n",
    "\n",
    "\n",
    "def rmse_model_batch(plot_result: bool):\n",
    "    \"\"\"Draw a circle with 2-dim coordinate as target variables.\"\"\"\n",
    "    X, y = gen_circle()\n",
    "    # Train a regressor on it\n",
    "    reg = xgb.XGBRegressor(tree_method=\"hist\", n_estimators=64)\n",
    "    reg.fit(X, y,)# eval_set=[(X, y)])\n",
    "\n",
    "    y_predt = reg.predict(X)\n",
    "    print(mean_absolute_error(y, y_predt))\n",
    "\n",
    "    if plot_result:\n",
    "        plot_predt(y, y_predt, \"multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_model(True)\n",
    "rmse_model_batch(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "929ea3a73902e04b651b50d7e8bff86e69e28c3f97df2b308a538a481df81bfd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
